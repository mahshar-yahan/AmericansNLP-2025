{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11025488,"sourceType":"datasetVersion","datasetId":6860858}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:27:46.168695Z","iopub.execute_input":"2025-03-19T06:27:46.168987Z","iopub.status.idle":"2025-03-19T06:27:46.482266Z","shell.execute_reply.started":"2025-03-19T06:27:46.168963Z","shell.execute_reply":"2025-03-19T06:27:46.481595Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/americannlp-task-2-dataset/maya-test.tsv\n/kaggle/input/americannlp-task-2-dataset/bribri-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-test.tsv\n/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/guarani-train.tsv\n/kaggle/input/americannlp-task-2-dataset/guarani-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/guarani-test.tsv\n/kaggle/input/americannlp-task-2-dataset/maya-train.tsv\n/kaggle/input/americannlp-task-2-dataset/bribri-test.tsv\n/kaggle/input/americannlp-task-2-dataset/maya-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-train.tsv\n/kaggle/input/americannlp-task-2-dataset/bribri-train.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%capture\n%pip install Dataset\n%pip install sacrebleu\n%pip install transformers\n%pip install sentencepiece\n%pip install datasets\n%pip install huggingface_hub\n%pip install bitsandbytes\n%pip install -U accelerate\n%pip install -U peft\n%pip install -U trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:27:46.483124Z","iopub.execute_input":"2025-03-19T06:27:46.483541Z","iopub.status.idle":"2025-03-19T06:28:27.122558Z","shell.execute_reply.started":"2025-03-19T06:27:46.483516Z","shell.execute_reply":"2025-03-19T06:28:27.121345Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set environment variable to help with memory allocation\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:27.124279Z","iopub.execute_input":"2025-03-19T06:28:27.124557Z","iopub.status.idle":"2025-03-19T06:28:27.128277Z","shell.execute_reply.started":"2025-03-19T06:28:27.124532Z","shell.execute_reply":"2025-03-19T06:28:27.127443Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHUGGINGFACE_TOKEN = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n\n!huggingface-cli login --token $HUGGINGFACE_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:27.129886Z","iopub.execute_input":"2025-03-19T06:28:27.130190Z","iopub.status.idle":"2025-03-19T06:28:28.177268Z","shell.execute_reply.started":"2025-03-19T06:28:27.130169Z","shell.execute_reply":"2025-03-19T06:28:28.176199Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nThe token `basic task` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `basic task`\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer,SFTConfig\nfrom trl import setup_chat_format\nfrom transformers import (\n                          AutoTokenizer,\n                          AutoModelForCausalLM, AutoModelForSeq2SeqLM,\n                          TrainingArguments,\n                          BitsAndBytesConfig,XGLMTokenizer, XGLMForCausalLM,\n                          pipeline, \n                          Trainer,\n                          DataCollatorWithPadding,\n                          logging)\nfrom sklearn.metrics import (accuracy_score,\n                             classification_report,\n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split\nfrom sacrebleu import corpus_bleu, corpus_chrf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:28.178405Z","iopub.execute_input":"2025-03-19T06:28:28.178678Z","iopub.status.idle":"2025-03-19T06:28:52.159772Z","shell.execute_reply.started":"2025-03-19T06:28:28.178652Z","shell.execute_reply":"2025-03-19T06:28:52.159085Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from accelerate import PartialState\ndevice_map={\"\": PartialState().process_index}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.160617Z","iopub.execute_input":"2025-03-19T06:28:52.161283Z","iopub.status.idle":"2025-03-19T06:28:52.190288Z","shell.execute_reply.started":"2025-03-19T06:28:52.161252Z","shell.execute_reply":"2025-03-19T06:28:52.189633Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Nahuati Omitlan Dataset","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain_df = pd.read_table('/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-train.tsv')\ndev_df = pd.read_table('/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-dev.tsv')\ntest_df = pd.read_table('/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-test.tsv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.191114Z","iopub.execute_input":"2025-03-19T06:28:52.191388Z","iopub.status.idle":"2025-03-19T06:28:52.220764Z","shell.execute_reply.started":"2025-03-19T06:28:52.191340Z","shell.execute_reply":"2025-03-19T06:28:52.220144Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"X_train = train_df\nX_eval = dev_df\nX_test_sub = test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.223025Z","iopub.execute_input":"2025-03-19T06:28:52.223256Z","iopub.status.idle":"2025-03-19T06:28:52.226900Z","shell.execute_reply.started":"2025-03-19T06:28:52.223236Z","shell.execute_reply":"2025-03-19T06:28:52.226233Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Tags to Instruction","metadata":{}},{"cell_type":"code","source":"# new type \ndef translate_tags_to_instruction(change):\n    \"\"\"\n    Translate the tags in the 'Change' field to full-form instructions, combining multiple instructions with 'and.'\n    \"\"\"\n    # Split the \"Change\" field into tags\n    instruction_tags = change.split(\", \")\n    instructions = []\n\n    # Define mapping dictionaries for each category\n    type_map = {\n        \"NEG\": \"Make the sentence negative\",\n        \"IMP\": \"Change the sentence to imperative mood\",\n        \"AFF\": \"Make the sentence affirmative\"\n    }\n\n    mood_map = {\n        \"DES\": \"Express desire or wish to perform the action\",\n        \"EXH\": \"Change to exhortative mood (encouraging or urging action)\",\n        \"ADVERS\": \"Express that the action was done despite difficulties\",\n        \"POT\": \"Express potential or ability to perform the action\",\n        \"COND\": \"Change to conditional mood\",\n        \"OPT\": \"Change to optative mood (expressing wish or hope)\",\n        \"INT\": \"Change to interrogative mood\",\n        \"NA\": \"Remove mood marking\",\n        \"IMP\": \"Change the sentence to imperative mood\"\n    }\n\n    tense_map = {\n        \"IPFV_HAB\": \"Change to habitual imperfective aspect\",\n        \"IPFV_REC\": \"Change to recent imperfective aspect\",\n        \"IPFV_PROG\": \"Change to progressive imperfective aspect\",\n        \"PRF_PROG\": \"Change to perfect progressive aspect\",\n        \"PRF_REC\": \"Change to recent perfect tense\",\n        \"FUT_POT\": \"Change to potential future tense\",\n        \"FUT_CER\": \"Change to certain future tense\",\n        \"PAS_PLU\": \"Change to pluperfect (past perfect) tense\",\n        \"PRE_SIM\": \"Change to present simple tense\",\n        \"PAS_SIM\": \"Change to past simple tense\",\n        \"FUT_SIM\": \"Change to future simple tense\"\n    }\n\n    aspect_map = {\n        \"IPFV\": \"Change to imperfective aspect\",\n        \"PFV\": \"Change to perfective aspect\",\n        \"INC\": \"Express the beginning or initiation of the action\",\n        \"DUR\": \"Express duration of the action\"\n    }\n\n    voice_map = {\n        \"MID\": \"Change to middle voice\"\n    }\n\n    absnum_map = {\n        \"PL\": \"Make the absolutive argument plural\",\n        \"NI\": \"Remove number marking from the absolutive argument\"\n    }\n\n    person_map = {\n        \"1_PL_EXC\": \"Change subject to first person plural exclusive\",\n        \"1_PL_INC\": \"Change subject to first person plural inclusive\",\n        \"2_PL\": \"Change subject to second person plural\",\n        \"3_PL\": \"Change subject to third person plural\",\n        \"2_SI\": \"Change subject to second person singular\",\n        \"3_SI\": \"Change subject to third person singular\",\n        \"1_SI\": \"Change subject to first person singular\",\n        \"1_PL\": \"Change subject to first person plural\"\n    }\n\n    poss_map = {\n        \"1_SI\": \"Change possessor to first person singular\",\n        \"1_PL\": \"Change possessor to first person plural\",\n        \"2_SI\": \"Change possessor to second person singular\",\n        \"2_PL\": \"Change possessor to second person plural\",\n        \"3_SI\": \"Change possessor to third person singular\",\n        \"3_PL\": \"Change possessor to third person plural\"\n    }\n\n    obj_map = {\n        \"1_SI\": \"Change object to first person singular\",\n        \"1_PL\": \"Change object to first person plural\",\n        \"2_SI\": \"Change object to second person singular\",\n        \"2_PL\": \"Change object to second person plural\",\n        \"3_SI\": \"Change object to third person singular\",\n        \"3_PL\": \"Change object to third person plural\"\n    }\n\n    iobj_map = {\n        \"1_SI\": \"Change indirect object to first person singular\",\n        \"1_PL\": \"Change indirect object to first person plural\",\n        \"2_SI\": \"Change indirect object to second person singular\",\n        \"2_PL\": \"Change indirect object to second person plural\",\n        \"3_SI\": \"Change indirect object to third person singular\",\n        \"3_PL\": \"Change indirect object to third person plural\"\n    }\n\n    honorific_map = {\n        \"HON:1\": \"Use honorific form\",\n        \"HON:NA\": \"Do not use honorific form\"\n    }\n\n    purposive_map = {\n        \"PURPOSIVE:VEN\": \"Express purpose or goal\",\n        \"PURPOSIVE:VET\": \"Express purpose or goal (alternative form)\",\n        \"PURPOSIVE:NA\": \"No purpose or goal indicated\"\n    }\n\n    transitivity_map = {\n        \"TRANSITIV:ITR\": \"Change to intransitive voice\"\n    }\n\n    # Translate each tag into a full-form instruction\n    for tag in instruction_tags:\n        if \":\" in tag:\n            category, value = tag.split(\":\")\n            if value != \"NA\":  # Ignore NA values\n                if category == \"TYPE\":\n                    instructions.append(type_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"MOOD\":\n                    instructions.append(mood_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"TENSE\":\n                    instructions.append(tense_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"ASPECT\":\n                    instructions.append(aspect_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"VOICE\":\n                    instructions.append(voice_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"ABSNUM\":\n                    instructions.append(absnum_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"PERSON[SUBJ]\":\n                    instructions.append(person_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"PERSON[POSS]\":\n                    instructions.append(poss_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"PERSON[OBJ]\":\n                    instructions.append(obj_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"PERSON[IOBJ]\":\n                    instructions.append(iobj_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"HON\":\n                    instructions.append(honorific_map.get(tag.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"PURPOSIVE\":\n                    instructions.append(purposive_map.get(tag.strip(), f\"{category}: {value.strip()}\"))\n                elif category == \"TRANSITIV\":\n                    instructions.append(transitivity_map.get(tag.strip(), f\"{category}: {value.strip()}\"))\n                else:\n                    instructions.append(f\"{category}: {value.strip()}\")\n        else:\n            # Handle tags without a colon\n            if tag in type_map:\n                instructions.append(type_map[tag])\n            elif tag in mood_map:\n                instructions.append(mood_map[tag])\n            elif tag in tense_map:\n                instructions.append(tense_map[tag])\n            elif tag in aspect_map:\n                instructions.append(aspect_map[tag])\n            elif tag in voice_map:\n                instructions.append(voice_map[tag])\n            elif tag in absnum_map:\n                instructions.append(absnum_map[tag])\n            else:\n                instructions.append(tag)\n\n    # Combine all instructions with 'and'\n    return ' and '.join(instructions)\n    \n# # Apply the function to the 'Change' column in both datasets\n# train_df['Instructions'] = train_df['Change'].apply(translate_tags_to_instruction)\n# dev_df['Instructions'] = dev_df['Change'].apply(translate_tags_to_instruction)\n\n# # Count the number of unknown instructions in both datasets\n# unknown_train = train_df['Instructions'].str.contains('Unknown').sum()\n# unknown_dev = dev_df['Instructions'].str.contains('Unknown').sum()\n\n# print(f\"Number of unknown instructions in training dataset: {unknown_train}\")\n# print(f\"Number of unknown instructions in development dataset: {unknown_dev}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.228632Z","iopub.execute_input":"2025-03-19T06:28:52.228878Z","iopub.status.idle":"2025-03-19T06:28:52.585098Z","shell.execute_reply.started":"2025-03-19T06:28:52.228858Z","shell.execute_reply":"2025-03-19T06:28:52.584118Z"}},"outputs":[{"name":"stdout","text":"Number of unknown instructions in training dataset: 0\nNumber of unknown instructions in development dataset: 0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# # Tag Function Tester\n\n# def translate_tags_to_instruction(change):\n#     \"\"\"\n#     Translate the tags in the 'Change' field to full-form instructions, combining multiple instructions with 'and.'\n#     \"\"\"\n#     # Split the \"Change\" field into tags\n#     instruction_tags = change.split(\", \")\n#     instructions = []\n\n#     # Define mapping dictionaries for each category\n#     type_map = {\n#         \"NEG\": \"Make the sentence negative\",\n#         \"IMP\": \"Change the sentence to imperative mood\",\n#         \"AFF\": \"Make the sentence affirmative\"\n#     }\n\n#     mode_map = {\n#         \"DES\": \"Express desire or wish to perform the action\",\n#         \"EXH\": \"Change to exhortative mood (encouraging or urging action)\",\n#         \"ADVERS\": \"Express that the action was done despite difficulties\",\n#         \"POT\": \"Express potential or ability to perform the action\",\n#         \"COND\": \"Change to conditional mood\",\n#         \"OPT\": \"Change to optative mood\",\n#         \"INT\": \"Change to interrogative mood\"\n#     }\n\n#     tense_map = {\n#         \"IPFV_HAB\": \"Change to habitual imperfective aspect\",\n#         \"IPFV_REC\": \"Change to recent imperfective aspect\",\n#         \"IPFV_PROG\": \"Change to progressive imperfective aspect\",\n#         \"PRF_PROG\": \"Change to perfect progressive aspect\",\n#         \"PRF_REC\": \"Change to recent perfect tense\",\n#         \"FUT_POT\": \"Change to potential future tense\",\n#         \"FUT_CER\": \"Change to certain future tense\",\n#         \"PAS_PLU\": \"Change to pluperfect (past perfect) tense\",\n#         \"PRE_SIM\": \"Change to present simple tense\",\n#         \"PAS_SIM\": \"Change to past simple tense\",\n#         \"FUT_SIM\": \"Change to future simple tense\"\n#     }\n\n#     aspect_map = {\n#         \"IPFV\": \"Change to imperfective aspect\",\n#         \"PFV\": \"Change to perfective aspect\",\n#         \"INC\": \"Express the beginning or initiation of the action\",\n#         \"DUR\": \"Express duration of the action\"\n#     }\n\n#     voice_map = {\n#         \"MID\": \"Change to middle voice\"\n#     }\n\n#     absnum_map = {\n#         \"PL\": \"Make the absolutive argument plural\",\n#         \"NI\": \"Remove number marking from the absolutive argument\"\n#     }\n\n#     # Key difference: removed space after colon in keys\n#     person_map = {\n#     # Without spaces after colon\n#     \"PERSON[SUBJ]:1_PL_EXC\": \"Change subject to first person plural exclusive\",\n#     \"PERSON[SUBJ]:1_PL_INC\": \"Change subject to first person plural inclusive\",\n#     \"PERSON[SUBJ]:2_PL\": \"Change subject to second person plural\",\n#     \"PERSON[SUBJ]:3_PL\": \"Change subject to third person plural\",\n#     \"PERSON[SUBJ]:2_SI\": \"Change subject to second person singular\",\n#     \"PERSON[SUBJ]:3_SI\": \"Change subject to third person singular\",\n#     \"PERSON[SUBJ]:1_SI\": \"Change subject to first person singular\",\n#     \"PERSON[POSS]:1_SI\": \"Change possessor to first person singular\",\n#     \"PERSON[POSS]:1_PL\": \"Change possessor to first person plural\",\n#     \"PERSON[POSS]:2_SI\": \"Change possessor to second person singular\",\n#     \"PERSON[POSS]:2_PL\": \"Change possessor to second person plural\",\n#     \"PERSON[POSS]:3_SI\": \"Change possessor to third person singular\",\n#     \"PERSON[POSS]:3_PL\": \"Change possessor to third person plural\",\n#     \"PERSON[OBJ]:1_SI\": \"Change object to first person singular\",\n#     \"PERSON[OBJ]:1_PL\": \"Change object to first person plural\",\n#     \"PERSON[OBJ]:2_SI\": \"Change object to second person singular\",\n#     \"PERSON[OBJ]:2_PL\": \"Change object to second person plural\",\n#     \"PERSON[OBJ]:3_SI\": \"Change object to third person singular\",\n#     \"PERSON[OBJ]:3_PL\": \"Change object to third person plural\",\n#     \"PERSON[IOBJ]:1_SI\": \"Change indirect object to first person singular\",\n#     \"PERSON[IOBJ]:1_PL\": \"Change indirect object to first person plural\",\n#     \"PERSON[IOBJ]:2_SI\": \"Change indirect object to second person singular\",\n#     \"PERSON[IOBJ]:2_PL\": \"Change indirect object to second person plural\",\n#     \"PERSON[IOBJ]:3_SI\": \"Change indirect object to third person singular\",\n#     \"PERSON[IOBJ]:3_PL\": \"Change indirect object to third person plural\",\n    \n#     # With spaces after colon\n#     \"PERSON[SUBJ]: 1_PL_EXC\": \"Change subject to first person plural exclusive\",\n#     \"PERSON[SUBJ]: 1_PL_INC\": \"Change subject to first person plural inclusive\",\n#     \"PERSON[SUBJ]: 2_PL\": \"Change subject to second person plural\",\n#     \"PERSON[SUBJ]: 3_PL\": \"Change subject to third person plural\",\n#     \"PERSON[SUBJ]: 2_SI\": \"Change subject to second person singular\",\n#     \"PERSON[SUBJ]: 3_SI\": \"Change subject to third person singular\",\n#     \"PERSON[SUBJ]: 1_SI\": \"Change subject to first person singular\",\n#     \"PERSON[POSS]: 1_SI\": \"Change possessor to first person singular\",\n#     \"PERSON[POSS]: 1_PL\": \"Change possessor to first person plural\",\n#     \"PERSON[POSS]: 2_SI\": \"Change possessor to second person singular\",\n#     \"PERSON[POSS]: 2_PL\": \"Change possessor to second person plural\",\n#     \"PERSON[POSS]: 3_SI\": \"Change possessor to third person singular\",\n#     \"PERSON[POSS]: 3_PL\": \"Change possessor to third person plural\",\n#     \"PERSON[OBJ]: 1_SI\": \"Change object to first person singular\",\n#     \"PERSON[OBJ]: 1_PL\": \"Change object to first person plural\",\n#     \"PERSON[OBJ]: 2_SI\": \"Change object to second person singular\",\n#     \"PERSON[OBJ]: 2_PL\": \"Change object to second person plural\",\n#     \"PERSON[OBJ]: 3_SI\": \"Change object to third person singular\",\n#     \"PERSON[OBJ]: 3_PL\": \"Change object to third person plural\",\n#     \"PERSON[IOBJ]: 1_SI\": \"Change indirect object to first person singular\",\n#     \"PERSON[IOBJ]: 1_PL\": \"Change indirect object to first person plural\",\n#     \"PERSON[IOBJ]: 2_SI\": \"Change indirect object to second person singular\",\n#     \"PERSON[IOBJ]: 2_PL\": \"Change indirect object to second person plural\",\n#     \"PERSON[IOBJ]: 3_SI\": \"Change indirect object to third person singular\",\n#     \"PERSON[IOBJ]: 3_PL\": \"Change indirect object to third person plural\"\n#     }\n\n#     mood_map = {\n#     \"IMP\": \"Change the sentence to imperative mood\",\n#     \"COND\": \"Change to conditional mood\",\n#     \"OPT\": \"Change to optative mood (expressing wish or hope)\",\n#     \"INT\": \"Change to interrogative mood\",\n#     \"NA\": \"Remove mood marking\",\n#     \"DES\": \"Express desire or wish to perform the action\",\n#     \"EXH\": \"Change to exhortative mood (encouraging or urging action)\",\n#     \"ADVERS\": \"Express that the action was done despite difficulties\",\n#     \"POT\": \"Express potential or ability to perform the action\"\n#     }\n#     honorific_map = {\n#         \"HON:1\": \"Use honorific form\",\n#         \"HON:NA\": \"Do not use honorific form\"\n#     }\n\n#     purposive_map = {\n#         \"PURPOSIVE:VEN\": \"Express purpose or goal\",\n#         \"PURPOSIVE:VET\": \"Express purpose or goal (alternative form)\",\n#         \"PURPOSIVE:NA\": \"No purpose or goal indicated\"\n#     }\n\n#     transitivity_map = {\n#         \"TRANSITIV:ITR\": \"Change to intransitive voice\"\n#     }\n\n#     # Translate each tag into a full-form instruction\n#     for tag in instruction_tags:\n#         if \":\" in tag:\n#             category, value = tag.split(\":\")\n#             if value != \"NA\":  # Ignore NA values\n#                 if category == \"TYPE\":\n#                     instructions.append(type_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"MOOD\":\n#                     instructions.append(mode_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"TENSE\":\n#                     instructions.append(tense_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"ASPECT\":\n#                     instructions.append(aspect_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"VOICE\":\n#                     instructions.append(voice_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"ABSNUM\":\n#                     instructions.append(absnum_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category.startswith(\"PERSON\"):\n#                     # Use the full tag as the key\n#                     instructions.append(person_map.get(tag.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"HON\":\n#                     instructions.append(honorific_map.get(tag.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"PURPOSIVE\":\n#                     instructions.append(purposive_map.get(tag.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"TRANSITIV\":\n#                     instructions.append(transitivity_map.get(tag.strip(), f\"{category}: {value.strip()}\"))\n#                 elif category == \"MOOD\":\n#                     instructions.append(mood_map.get(value.strip(), f\"{category}: {value.strip()}\"))\n#                 else:\n#                     instructions.append(f\"{category}: {value.strip()}\")\n#         else:\n#             # Handle tags without a colon\n#             if tag in type_map:\n#                 instructions.append(type_map[tag])\n#             elif tag in mode_map:\n#                 instructions.append(mode_map[tag])\n#             elif tag in tense_map:\n#                 instructions.append(tense_map[tag])\n#             elif tag in aspect_map:\n#                 instructions.append(aspect_map[tag])\n#             elif tag in voice_map:\n#                 instructions.append(voice_map[tag])\n#             elif tag in absnum_map:\n#                 instructions.append(absnum_map[tag])\n#             else:\n#                 instructions.append(tag)\n\n#     # Combine all instructions with 'and'\n#     return ' and '.join(instructions)\n\n\n# # Example usage\n# instruction = \"PERSON[SUBJ]:1_PL, TENSE:FUT_SIM, TYPE:AFF\"\n# print(translate_tags_to_instruction(instruction))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.586411Z","iopub.execute_input":"2025-03-19T06:28:52.586828Z","iopub.status.idle":"2025-03-19T06:28:52.610842Z","shell.execute_reply.started":"2025-03-19T06:28:52.586782Z","shell.execute_reply":"2025-03-19T06:28:52.610156Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dev_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.611535Z","iopub.execute_input":"2025-03-19T06:28:52.611742Z","iopub.status.idle":"2025-03-19T06:28:52.644912Z","shell.execute_reply.started":"2025-03-19T06:28:52.611723Z","shell.execute_reply":"2025-03-19T06:28:52.644234Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                     ID             Source  \\\n0    NahuatlOmitlan0001       oualah nouan   \n1    NahuatlOmitlan0002       amo mococoua   \n2    NahuatlOmitlan0003    ualasqueh nouan   \n3    NahuatlOmitlan0004    ualasqueh nouan   \n4    NahuatlOmitlan0005  neh amo nitomauac   \n..                  ...                ...   \n171  NahuatlOmitlan0172      oniualah iuan   \n172  NahuatlOmitlan0173     tiuitzeh mouan   \n173  NahuatlOmitlan0174     oniualaya iuan   \n174  NahuatlOmitlan0175        niinconeuan   \n175  NahuatlOmitlan0176          nimoconeu   \n\n                                                Change  \\\n0    HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUB...   \n1                            ASPECT:PFV, TENSE:PAS_SIM   \n2    ASPECT:IPFV, PERSON[POSS]:3_PL, TENSE:PAS_SIM,...   \n3    HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUB...   \n4           PERSON[SUBJ]:1_PL, TENSE:FUT_SIM, TYPE:AFF   \n..                                                 ...   \n171  PERSON[POSS]:1_SI, PERSON[SUBJ]:3_PL, TENSE:FU...   \n172  MOOD:IMP, PERSON[POSS]:1_SI, PERSON[SUBJ]:2_SI...   \n173  PERSON[POSS]:1_SI, PERSON[SUBJ]:3_PL, TENSE:FU...   \n174               PERSON[POSS]:3_SI, PERSON[SUBJ]:3_SI   \n175               PERSON[POSS]:3_SI, PERSON[SUBJ]:3_SI   \n\n                           Target  \\\n0                 xonuiqueh touan   \n1                    amo omococoh   \n2              amo oualayah inuan   \n3                 xonuiqueh touan   \n4    tehuan tiisqueh titomauaqueh   \n..                            ...   \n171               ualasqueh nouan   \n172             amo xiuiqui nouan   \n173               ualasqueh nouan   \n174                    yeh iconeu   \n175                    yeh iconeu   \n\n                                          Instructions  \n0    Use honorific form and Change the sentence to ...  \n1    Change to perfective aspect and Change to past...  \n2    Change to imperfective aspect and Change posse...  \n3    Use honorific form and Change the sentence to ...  \n4    Change subject to first person plural and Chan...  \n..                                                 ...  \n171  Change possessor to first person singular and ...  \n172  Change the sentence to imperative mood and Cha...  \n173  Change possessor to first person singular and ...  \n174  Change possessor to third person singular and ...  \n175  Change possessor to third person singular and ...  \n\n[176 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Change</th>\n      <th>Target</th>\n      <th>Instructions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NahuatlOmitlan0001</td>\n      <td>oualah nouan</td>\n      <td>HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUB...</td>\n      <td>xonuiqueh touan</td>\n      <td>Use honorific form and Change the sentence to ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NahuatlOmitlan0002</td>\n      <td>amo mococoua</td>\n      <td>ASPECT:PFV, TENSE:PAS_SIM</td>\n      <td>amo omococoh</td>\n      <td>Change to perfective aspect and Change to past...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NahuatlOmitlan0003</td>\n      <td>ualasqueh nouan</td>\n      <td>ASPECT:IPFV, PERSON[POSS]:3_PL, TENSE:PAS_SIM,...</td>\n      <td>amo oualayah inuan</td>\n      <td>Change to imperfective aspect and Change posse...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NahuatlOmitlan0004</td>\n      <td>ualasqueh nouan</td>\n      <td>HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUB...</td>\n      <td>xonuiqueh touan</td>\n      <td>Use honorific form and Change the sentence to ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NahuatlOmitlan0005</td>\n      <td>neh amo nitomauac</td>\n      <td>PERSON[SUBJ]:1_PL, TENSE:FUT_SIM, TYPE:AFF</td>\n      <td>tehuan tiisqueh titomauaqueh</td>\n      <td>Change subject to first person plural and Chan...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>NahuatlOmitlan0172</td>\n      <td>oniualah iuan</td>\n      <td>PERSON[POSS]:1_SI, PERSON[SUBJ]:3_PL, TENSE:FU...</td>\n      <td>ualasqueh nouan</td>\n      <td>Change possessor to first person singular and ...</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>NahuatlOmitlan0173</td>\n      <td>tiuitzeh mouan</td>\n      <td>MOOD:IMP, PERSON[POSS]:1_SI, PERSON[SUBJ]:2_SI...</td>\n      <td>amo xiuiqui nouan</td>\n      <td>Change the sentence to imperative mood and Cha...</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>NahuatlOmitlan0174</td>\n      <td>oniualaya iuan</td>\n      <td>PERSON[POSS]:1_SI, PERSON[SUBJ]:3_PL, TENSE:FU...</td>\n      <td>ualasqueh nouan</td>\n      <td>Change possessor to first person singular and ...</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>NahuatlOmitlan0175</td>\n      <td>niinconeuan</td>\n      <td>PERSON[POSS]:3_SI, PERSON[SUBJ]:3_SI</td>\n      <td>yeh iconeu</td>\n      <td>Change possessor to third person singular and ...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>NahuatlOmitlan0176</td>\n      <td>nimoconeu</td>\n      <td>PERSON[POSS]:3_SI, PERSON[SUBJ]:3_SI</td>\n      <td>yeh iconeu</td>\n      <td>Change possessor to third person singular and ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>176 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Prompt Function","metadata":{}},{"cell_type":"code","source":"# Define functions for generating prompts\ndef generate_prompt(row):\n    \"\"\"\n    Generate a structured training prompt for a given data point.\n    \"\"\"\n    # instruction = translate_tags_to_instruction(row[\"Change\"])\n    return (\n        f\"Language: Nahuatl Omitlan\\n\"\n        f\"Task: Transform the Source sentence into the Target sentence based on the given instruction.\\n\\n\"\n        f\"Instruction: {row['Change']}\\n\"\n        f\"Source: {row['Source']}\\n\"\n        f\"Target: {row['Target']}\"\n    )\n\ndef generate_test_prompt(row):\n    \"\"\"\n    Generate a structured test prompt for a given data point.\n    \"\"\"\n    # instruction = translate_tags_to_instruction(row[\"Change\"])\n    return (\n        f\"Language: Nahuatl Omitlan\\n\"\n        f\"Task: Transform the Source sentence into the Target sentence based on the given instruction.\\n\\n\"\n        f\"Instruction: {row['Change']}\\n\"\n        f\"Source: {row['Source']}\\n\"\n        f\"Provide only the transformed Target sentence.\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.645586Z","iopub.execute_input":"2025-03-19T06:28:52.645801Z","iopub.status.idle":"2025-03-19T06:28:52.649802Z","shell.execute_reply.started":"2025-03-19T06:28:52.645781Z","shell.execute_reply":"2025-03-19T06:28:52.648846Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# def generate_prompt(data_point):\n#     \"\"\"\n#     Generate a structured training prompt for a given data point.\n#     \"\"\"\n#     return (\n#         f\"Language: Nahuatl Omitlan\\n\"\n#         f\"Task: Rewrite and transform the Source sentence into the Target sentence based on the provided instruction.\\n\\n\"\n#         f\"Instruction: {data_point['Change']}\\n\"\n#         f\"Source: {data_point['Source']}\\n\"\n#         f\"Target: {data_point['Target']}\"\n#     )\n\n# def generate_test_prompt(data_point):\n#     \"\"\"\n#     Generate a structured test prompt for a given data point.\n#     \"\"\"\n#     return (\n#         f\"Language: Nahuatl Omitlan\\n\"\n#         f\"Task: Rewrite and transform the Source sentence into the Target sentence based on the provided instruction.\\n\\n\"\n#         f\"Instruction: {data_point['Change']}\\n\"\n#         f\"Source: {data_point['Source']}\\n\"\n#         f\"Provide only the rewritten Target sentence.\"\n#     )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.650534Z","iopub.execute_input":"2025-03-19T06:28:52.650742Z","iopub.status.idle":"2025-03-19T06:28:52.665834Z","shell.execute_reply.started":"2025-03-19T06:28:52.650724Z","shell.execute_reply":"2025-03-19T06:28:52.665054Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# # zero shot prompting type 1\n# def generate_prompt(data_point):\n#     \"\"\"\n#     Generate a structured training prompt for a given data point.\n#     \"\"\"\n#     return f\"\"\"Language: Nahuatl Omitlan,rewrite and change the Source sentence to the Target sentence according to the given instruction.\n# Instruction: {data_point[\"Change\"]}\n# Source: {data_point[\"Source\"]}\n# Target: {data_point[\"Target\"]}\n# \"\"\".strip()\n\n# def generate_test_prompt(data_point):\n#     return f\"\"\"\n# Language: Nahuatl Omitlan,rewrite and change the Source sentence to the Target sentence according to the given instruction.\n# Instruction: {data_point[\"Change\"]}\n# Source: {data_point[\"Source\"]}\n# Provide only the Target sentence nothing else.\n# Target:\"\"\".strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.666647Z","iopub.execute_input":"2025-03-19T06:28:52.666924Z","iopub.status.idle":"2025-03-19T06:28:52.679835Z","shell.execute_reply.started":"2025-03-19T06:28:52.666904Z","shell.execute_reply":"2025-03-19T06:28:52.679203Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# # Generate prompts for training and evaluation dataa\n# X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n# X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.680485Z","iopub.execute_input":"2025-03-19T06:28:52.680723Z","iopub.status.idle":"2025-03-19T06:28:52.695989Z","shell.execute_reply.started":"2025-03-19T06:28:52.680696Z","shell.execute_reply":"2025-03-19T06:28:52.695252Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Generate prompts for training and evaluation data\nX_train[\"text\"] = X_train.apply(generate_prompt, axis=1)\nX_eval[\"text\"] = X_eval.apply(generate_prompt, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.696819Z","iopub.execute_input":"2025-03-19T06:28:52.697076Z","iopub.status.idle":"2025-03-19T06:28:52.717994Z","shell.execute_reply.started":"2025-03-19T06:28:52.697044Z","shell.execute_reply":"2025-03-19T06:28:52.717421Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Convert to datasets\ntrain_data = Dataset.from_pandas(X_train[[\"text\"]])\neval_data = Dataset.from_pandas(X_eval[[\"text\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.718998Z","iopub.execute_input":"2025-03-19T06:28:52.719208Z","iopub.status.idle":"2025-03-19T06:28:52.745494Z","shell.execute_reply.started":"2025-03-19T06:28:52.719190Z","shell.execute_reply":"2025-03-19T06:28:52.744761Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Create a new DataFrame for test prompts\ntest_data = pd.DataFrame({\n    \"Change\": X_eval[\"Change\"],\n    \"Source\": X_eval[\"Source\"]\n})\n# Generate prompts for test data\nX_test = pd.DataFrame(test_data.apply(lambda row: generate_test_prompt(row), axis=1), columns=[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.746440Z","iopub.execute_input":"2025-03-19T06:28:52.746630Z","iopub.status.idle":"2025-03-19T06:28:52.752498Z","shell.execute_reply.started":"2025-03-19T06:28:52.746613Z","shell.execute_reply":"2025-03-19T06:28:52.751700Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Set the device (GPU if available)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.753153Z","iopub.execute_input":"2025-03-19T06:28:52.753340Z","iopub.status.idle":"2025-03-19T06:28:52.766875Z","shell.execute_reply.started":"2025-03-19T06:28:52.753315Z","shell.execute_reply":"2025-03-19T06:28:52.766064Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.767817Z","iopub.execute_input":"2025-03-19T06:28:52.768092Z","iopub.status.idle":"2025-03-19T06:28:52.782755Z","shell.execute_reply.started":"2025-03-19T06:28:52.768065Z","shell.execute_reply":"2025-03-19T06:28:52.782110Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Model Load (Llama 3.2-3B Instruct)","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained model and tokenizer\nbase_model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=\"float16\",\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name,\n    device_map=\"auto\",\n    torch_dtype=\"float16\",\n    quantization_config=bnb_config, \n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:28:52.783469Z","iopub.execute_input":"2025-03-19T06:28:52.783715Z","iopub.status.idle":"2025-03-19T06:29:35.059164Z","shell.execute_reply.started":"2025-03-19T06:28:52.783687Z","shell.execute_reply":"2025-03-19T06:29:35.058427Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49418acfb1d146db8a20f152f1d183d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81454402fb2b4891a744f0f6fbbf1da4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5863d4ca14b4786b644508a7625dc8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e05fcfd892ba45b4b57d4db79adf5831"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1faa81f93574ccaab2c76fe527e7e91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5927157c8724ba2aac93863fe44b3d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568bb567f77e40dda02cc0ed04dae69e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb57f44c0854127a0100fbae132e889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ceb5a68fd36433eaac2c9c0a307fef6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d087bf0a482b43478efd18aad4d2fe3a"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Move the model to the GPU\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:29:35.059976Z","iopub.execute_input":"2025-03-19T06:29:35.060182Z","iopub.status.idle":"2025-03-19T06:29:35.079158Z","shell.execute_reply.started":"2025-03-19T06:29:35.060165Z","shell.execute_reply":"2025-03-19T06:29:35.078476Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# # Define a custom predict function\n# def predict(test, model, tokenizer):\n#     y_pred = []\n    \n#     for i in tqdm(range(len(test))):\n#         prompt = test.iloc[i][\"text\"]\n#         inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n        \n#         # Generate text using the model directly\n#         outputs = model.generate(**inputs, max_length=100, num_beams=4, no_repeat_ngram_size=3).to(device)\n        \n#         generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True).to(device)\n#         transformed_sentence = generated_text.split(\"Target:\")[-1].strip()\n\n#         if transformed_sentence:  \n#             y_pred.append(transformed_sentence)\n#         else:\n#             y_pred.append(\"ERROR\")  # Handle empty outputs\n    \n#     return y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:29:35.082229Z","iopub.execute_input":"2025-03-19T06:29:35.082448Z","iopub.status.idle":"2025-03-19T06:29:35.438826Z","shell.execute_reply.started":"2025-03-19T06:29:35.082425Z","shell.execute_reply":"2025-03-19T06:29:35.438028Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Predict and Post Processing","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom transformers import pipeline\nimport string\ndef clean_prediction(text):\n    \"\"\"\n    Extracts the expected transformed sentence from the generated output.\n    Stops processing as soon as a punctuation mark is encountered.\n    \"\"\"\n    text = text.strip()\n\n    # Extract text after \"Target:\" marker\n    if \"Target:\" in text:\n        text = text.split(\"Target:\")[-1].strip()\n\n    # Take only the first line to remove unwanted repetitions\n    text = text.split(\"\\n\")[0].strip()\n\n    # Stop at the first punctuation (e.g., period, comma, etc.)\n    for punctuation in string.punctuation:\n        if punctuation in text:\n            text = text.split(punctuation)[0].strip()\n            break\n\n    return text\n\n\ndef predict(test, model, tokenizer):\n    \"\"\"\n    Generate predictions for the test dataset without using a dataset format.\n    \"\"\"\n    y_pred = []\n    \n    # Define pipeline outside loop for efficiency\n    pipe = pipeline(task=\"text-generation\", \n                    model=model, \n                    tokenizer=tokenizer, \n                    max_new_tokens=20,  # Limit length to avoid extra output\n                    temperature=0.1,  # Make output more deterministic\n                    )  \n\n    for i in tqdm(range(len(test))):\n        prompt = test.iloc[i][\"text\"]  # Use already pre-generated test prompts\n        result = pipe(prompt)\n        \n        generated_text = result[0]['generated_text']\n        transformed_sentence = clean_prediction(generated_text)\n        y_pred.append(transformed_sentence if transformed_sentence else \"ERROR\")  # Handle empty output\n\n    return y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:29:35.440505Z","iopub.execute_input":"2025-03-19T06:29:35.440737Z","iopub.status.idle":"2025-03-19T06:29:35.450737Z","shell.execute_reply.started":"2025-03-19T06:29:35.440717Z","shell.execute_reply":"2025-03-19T06:29:35.450043Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Evaluate the model before fine-tuning\ny_pred_before_fine_tune = predict(X_test, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:29:35.451444Z","iopub.execute_input":"2025-03-19T06:29:35.451634Z","iopub.status.idle":"2025-03-19T06:31:58.960848Z","shell.execute_reply.started":"2025-03-19T06:29:35.451616Z","shell.execute_reply":"2025-03-19T06:31:58.960099Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n  6%|â–Œ         | 10/176 [00:08<02:21,  1.17it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [02:23<00:00,  1.23it/s]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Evaluate Function","metadata":{}},{"cell_type":"code","source":"# Evaluate the predictions\ndef evaluate(y_true, y_pred):\n    bleu = corpus_bleu(y_pred, [y_true])\n    print(f\"BLEU score: {bleu.score:.2f}\")\n\n    chrf = corpus_chrf(y_pred, [y_true])\n    print(f\"chrF score: {chrf.score:.2f}\")\n\n    for i in range(min(5, len(y_true))):\n        print(f\"\\nMain Prompt: {X_test.iloc[i]['text']}\")\n        print(f\"Expected Sentence: {y_true[i]}\")\n        print(f\"Prediction: {y_pred[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:31:58.961591Z","iopub.execute_input":"2025-03-19T06:31:58.961813Z","iopub.status.idle":"2025-03-19T06:31:58.966605Z","shell.execute_reply.started":"2025-03-19T06:31:58.961785Z","shell.execute_reply":"2025-03-19T06:31:58.965657Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Evaluate the model\ny_true = X_eval[\"Target\"]\n\n# Evaluate the model before fine-tuning\nprint(\"\\nOriginal Model Evaluation Before Fine Tuning:\")\nevaluate(y_true.tolist(), y_pred_before_fine_tune)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:31:58.967300Z","iopub.execute_input":"2025-03-19T06:31:58.967569Z","iopub.status.idle":"2025-03-19T06:31:59.009091Z","shell.execute_reply.started":"2025-03-19T06:31:58.967548Z","shell.execute_reply":"2025-03-19T06:31:59.008206Z"}},"outputs":[{"name":"stdout","text":"\nOriginal Model Evaluation Before Fine Tuning:\nBLEU score: 0.65\nchrF score: 13.08\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUBJ]:2_PL, TENSE:PRE_SIM\nSource: oualah nouan\nProvide only the transformed Target sentence.\nExpected Sentence: xonuiqueh touan\nPrediction: oualah nouan\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: ASPECT:PFV, TENSE:PAS_SIM\nSource: amo mococoua\nProvide only the transformed Target sentence.\nExpected Sentence: amo omococoh\nPrediction: Language\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: ASPECT:IPFV, PERSON[POSS]:3_PL, TENSE:PAS_SIM, TYPE:NEG\nSource: ualasqueh nouan\nProvide only the transformed Target sentence.\nExpected Sentence: amo oualayah inuan\nPrediction: Language\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUBJ]:2_PL, TENSE:PRE_SIM\nSource: ualasqueh nouan\nProvide only the transformed Target sentence.\nExpected Sentence: xonuiqueh touan\nPrediction: ualasqueh nouan\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: PERSON[SUBJ]:1_PL, TENSE:FUT_SIM, TYPE:AFF\nSource: neh amo nitomauac\nProvide only the transformed Target sentence.\nExpected Sentence: tehuan tiisqueh titomauaqueh\nPrediction: Language\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Define LoRA configuration\ndef find_all_linear_names(model):\n    cls = torch.nn.Linear\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T07:05:38.422306Z","iopub.execute_input":"2025-03-19T07:05:38.422658Z","iopub.status.idle":"2025-03-19T07:05:38.431284Z","shell.execute_reply.started":"2025-03-19T07:05:38.422635Z","shell.execute_reply":"2025-03-19T07:05:38.430423Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=4,\n    lora_alpha=8,\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T07:05:40.495709Z","iopub.execute_input":"2025-03-19T07:05:40.496014Z","iopub.status.idle":"2025-03-19T07:05:40.499843Z","shell.execute_reply.started":"2025-03-19T07:05:40.495989Z","shell.execute_reply":"2025-03-19T07:05:40.498937Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Set up training arguments\ntraining_arguments = SFTConfig(\n    output_dir=\"./results\",\n    num_train_epochs=5,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    save_steps=1000,\n    dataset_text_field=\"text\",\n    max_seq_length=512,\n    packing=False,\n    logging_steps=500,\n    learning_rate=2e-4,\n    weight_decay=0.01,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"none\",\n    eval_strategy=\"steps\",\n    eval_steps=50,  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T07:06:41.109995Z","iopub.execute_input":"2025-03-19T07:06:41.110294Z","iopub.status.idle":"2025-03-19T07:06:41.137851Z","shell.execute_reply.started":"2025-03-19T07:06:41.110272Z","shell.execute_reply":"2025-03-19T07:06:41.137135Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Initialize the SFTTrainer\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=lora_config,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T07:06:43.211285Z","iopub.execute_input":"2025-03-19T07:06:43.211588Z","iopub.status.idle":"2025-03-19T07:06:43.289268Z","shell.execute_reply.started":"2025-03-19T07:06:43.211563Z","shell.execute_reply":"2025-03-19T07:06:43.288028Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-50-1a90b2d52780>:2: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n  trainer = SFTTrainer(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-1a90b2d52780>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize the SFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# PEFT configuration and model wrapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Handle the tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m_prepare_peft_model\u001b[0;34m(self, model, peft_config, args)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautocast_adapter_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Handle bf16 casting for 4-bit models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/mapping.py\u001b[0m in \u001b[0;36mget_peft_model\u001b[0;34m(model, peft_config, adapter_name, mixed, autocast_adapter_dtype, revision, low_cpu_mem_usage)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_prompt_learning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mpeft_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_prompt_learning_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     return MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config.task_type](\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, peft_config, adapter_name, **kwargs)\u001b[0m\n\u001b[1;32m   1682\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     ) -> None:\n\u001b[0;32m-> 1684\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prepare_inputs_for_generation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, peft_config, adapter_name, autocast_adapter_dtype, low_cpu_mem_usage)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_empty_weights\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_additional_trainable_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, config, adapter_name, low_cpu_mem_usage)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_new_adapter_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLoraConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, peft_config, adapter_name, low_cpu_mem_usage)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mPeftType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXLORA\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mPeftType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXLORA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Copy the peft_config in the injected model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36minject_adapter\u001b[0;34m(self, model, adapter_name, autocast_adapter_dtype, low_cpu_mem_usage)\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_empty_weights\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_and_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargeted_module_names\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muses_dummy_target_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m_create_and_replace\u001b[0;34m(self, lora_config, adapter_name, target, target_name, parent, current_key)\u001b[0m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mnew_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_new_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlora_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madapter_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_adapters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;31m# adding an additional adapter: it is not automatically trainable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m_create_new_module\u001b[0;34m(lora_config, adapter_name, target, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# no module could be matched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    361\u001b[0m                 \u001b[0;34mf\"Target module {target} is not supported. Currently, only the following modules are supported: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;34m\"`torch.nn.Linear`, `torch.nn.Embedding`, `torch.nn.Conv2d`, `torch.nn.Conv3d`, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Target module Dropout(p=0.1, inplace=False) is not supported. Currently, only the following modules are supported: `torch.nn.Linear`, `torch.nn.Embedding`, `torch.nn.Conv2d`, `torch.nn.Conv3d`, `transformers.pytorch_utils.Conv1D`."],"ename":"ValueError","evalue":"Target module Dropout(p=0.1, inplace=False) is not supported. Currently, only the following modules are supported: `torch.nn.Linear`, `torch.nn.Embedding`, `torch.nn.Conv2d`, `torch.nn.Conv3d`, `transformers.pytorch_utils.Conv1D`.","output_type":"error"}],"execution_count":50},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:32:00.429287Z","iopub.execute_input":"2025-03-19T06:32:00.429590Z","iopub.status.idle":"2025-03-19T06:51:03.646818Z","shell.execute_reply.started":"2025-03-19T06:32:00.429567Z","shell.execute_reply":"2025-03-19T06:51:03.646108Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='975' max='975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [975/975 19:01, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>No log</td>\n      <td>1.425380</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>No log</td>\n      <td>1.242674</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>No log</td>\n      <td>1.161679</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>No log</td>\n      <td>1.178118</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>No log</td>\n      <td>1.197610</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>No log</td>\n      <td>1.209590</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>No log</td>\n      <td>1.224546</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>No log</td>\n      <td>1.240438</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>No log</td>\n      <td>1.290197</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.160300</td>\n      <td>1.208996</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.160300</td>\n      <td>1.233884</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.160300</td>\n      <td>1.237671</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.160300</td>\n      <td>1.242896</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.160300</td>\n      <td>1.251397</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.160300</td>\n      <td>1.259140</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.160300</td>\n      <td>1.327533</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.160300</td>\n      <td>1.309624</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.160300</td>\n      <td>1.334238</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.160300</td>\n      <td>1.291096</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=975, training_loss=0.8182956167367789, metrics={'train_runtime': 1142.7373, 'train_samples_per_second': 1.711, 'train_steps_per_second': 0.853, 'total_flos': 2573071726061568.0, 'train_loss': 0.8182956167367789})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Evaluate the model after fine-tuning\ny_pred_after_fine_tune = predict(X_test, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:51:03.647648Z","iopub.execute_input":"2025-03-19T06:51:03.647903Z","iopub.status.idle":"2025-03-19T06:56:14.708536Z","shell.execute_reply.started":"2025-03-19T06:51:03.647882Z","shell.execute_reply":"2025-03-19T06:56:14.707665Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [05:11<00:00,  1.77s/it]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Evaluate the model\ny_true = X_eval[\"Target\"]\n\n# Evaluate the model before fine-tuning\nprint(\"\\nOriginal Model Evaluation After Fine Tuning:\")\nevaluate(y_true.tolist(), y_pred_after_fine_tune)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:56:14.709382Z","iopub.execute_input":"2025-03-19T06:56:14.709607Z","iopub.status.idle":"2025-03-19T06:56:14.740536Z","shell.execute_reply.started":"2025-03-19T06:56:14.709587Z","shell.execute_reply":"2025-03-19T06:56:14.739549Z"}},"outputs":[{"name":"stdout","text":"\nOriginal Model Evaluation After Fine Tuning:\nBLEU score: 0.25\nchrF score: 18.71\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUBJ]:2_PL, TENSE:PRE_SIM\nSource: oualah nouan\nProvide only the transformed Target sentence.\nExpected Sentence: xonuiqueh touan\nPrediction: xicchihchiua motlaxcalmeh ousideh qu\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: ASPECT:PFV, TENSE:PAS_SIM\nSource: amo mococoua\nProvide only the transformed Target sentence.\nExpected Sentence: amo omococoh\nPrediction: amo occochtito conetl\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: ASPECT:IPFV, PERSON[POSS]:3_PL, TENSE:PAS_SIM, TYPE:NEG\nSource: ualasqueh nouan\nProvide only the transformed Target sentence.\nExpected Sentence: amo oualayah inuan\nPrediction: amo onlasohtla oinlan\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: HON:1, MOOD:IMP, PERSON[POSS]:1_PL, PERSON[SUBJ]:2_PL, TENSE:PRE_SIM\nSource: ualasqueh nouan\nProvide only the transformed Target sentence.\nExpected Sentence: xonuiqueh touan\nPrediction: xicchihchiua motlaxcalmeh\n\nMain Prompt: Language: Nahuatl Omitlan\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: PERSON[SUBJ]:1_PL, TENSE:FUT_SIM, TYPE:AFF\nSource: neh amo nitomauac\nProvide only the transformed Target sentence.\nExpected Sentence: tehuan tiisqueh titomauaqueh\nPrediction: tiquimpiyasqueh siqui yolcameh\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"y_true","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:56:14.741590Z","iopub.execute_input":"2025-03-19T06:56:14.741886Z","iopub.status.idle":"2025-03-19T06:56:14.762210Z","shell.execute_reply.started":"2025-03-19T06:56:14.741849Z","shell.execute_reply":"2025-03-19T06:56:14.761380Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0                   xonuiqueh touan\n1                      amo omococoh\n2                amo oualayah inuan\n3                   xonuiqueh touan\n4      tehuan tiisqueh titomauaqueh\n                   ...             \n171                 ualasqueh nouan\n172               amo xiuiqui nouan\n173                 ualasqueh nouan\n174                      yeh iconeu\n175                      yeh iconeu\nName: Target, Length: 176, dtype: object"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"## Dev Submission","metadata":{}},{"cell_type":"code","source":"dev_pd = pd.DataFrame(y_pred_after_fine_tune, columns=['Values'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:56:14.763078Z","iopub.execute_input":"2025-03-19T06:56:14.763390Z","iopub.status.idle":"2025-03-19T06:56:14.778371Z","shell.execute_reply.started":"2025-03-19T06:56:14.763342Z","shell.execute_reply":"2025-03-19T06:56:14.777535Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"dev_pd.to_csv('syntax_squad_nahuatl_omitlan_dev_output.tsv', sep='\\t', index=False, header=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:56:14.779118Z","iopub.execute_input":"2025-03-19T06:56:14.779321Z","iopub.status.idle":"2025-03-19T06:56:14.800078Z","shell.execute_reply.started":"2025-03-19T06:56:14.779302Z","shell.execute_reply":"2025-03-19T06:56:14.799273Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(\"syntax_squad_nahuatl_omitlan_dev_output.tsv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:56:14.800987Z","iopub.execute_input":"2025-03-19T06:56:14.801211Z","iopub.status.idle":"2025-03-19T06:56:14.812565Z","shell.execute_reply.started":"2025-03-19T06:56:14.801190Z","shell.execute_reply":"2025-03-19T06:56:14.811826Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/syntax_squad_nahuatl_omitlan_dev_output.tsv","text/html":"<a href='syntax_squad_nahuatl_omitlan_dev_output.tsv' target='_blank'>syntax_squad_nahuatl_omitlan_dev_output.tsv</a><br>"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## Test Submission","metadata":{}},{"cell_type":"code","source":"# Create a new DataFrame for test prompts\ntest_data_sub = pd.DataFrame({\n    \"Change\": X_test_sub[\"Change\"],\n    \"Source\": X_test_sub[\"Source\"]\n})\n# Generate prompts for test data\nX_test_sub = pd.DataFrame(test_data_sub.apply(lambda row: generate_test_prompt(row), axis=1), columns=[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:56:14.813435Z","iopub.execute_input":"2025-03-19T06:56:14.813726Z","iopub.status.idle":"2025-03-19T06:56:14.836807Z","shell.execute_reply.started":"2025-03-19T06:56:14.813696Z","shell.execute_reply":"2025-03-19T06:56:14.836037Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Evaluate the model before fine-tuning\ny_pred_test = predict(X_test_sub, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:56:14.837667Z","iopub.execute_input":"2025-03-19T06:56:14.837939Z","iopub.status.idle":"2025-03-19T06:59:45.812452Z","shell.execute_reply.started":"2025-03-19T06:56:14.837910Z","shell.execute_reply":"2025-03-19T06:59:45.811548Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [03:30<00:00,  1.76s/it]\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"test_pd = pd.DataFrame(y_pred_test, columns=['Values'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:59:45.813461Z","iopub.execute_input":"2025-03-19T06:59:45.813728Z","iopub.status.idle":"2025-03-19T06:59:45.817813Z","shell.execute_reply.started":"2025-03-19T06:59:45.813704Z","shell.execute_reply":"2025-03-19T06:59:45.816907Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"test_pd.to_csv('syntax_squad_nahuatl_omitlan_test_output.tsv', sep='\\t', index=False, header=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:59:45.818531Z","iopub.execute_input":"2025-03-19T06:59:45.818718Z","iopub.status.idle":"2025-03-19T06:59:45.837960Z","shell.execute_reply.started":"2025-03-19T06:59:45.818700Z","shell.execute_reply":"2025-03-19T06:59:45.837177Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(\"syntax_squad_nahuatl_omitlan_test_output.tsv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:59:45.838767Z","iopub.execute_input":"2025-03-19T06:59:45.838959Z","iopub.status.idle":"2025-03-19T06:59:45.854950Z","shell.execute_reply.started":"2025-03-19T06:59:45.838941Z","shell.execute_reply":"2025-03-19T06:59:45.854318Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/syntax_squad_nahuatl_omitlan_test_output.tsv","text/html":"<a href='syntax_squad_nahuatl_omitlan_test_output.tsv' target='_blank'>syntax_squad_nahuatl_omitlan_test_output.tsv</a><br>"},"metadata":{}}],"execution_count":43}]}