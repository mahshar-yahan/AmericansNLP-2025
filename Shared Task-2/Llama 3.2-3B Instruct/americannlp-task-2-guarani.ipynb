{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11025488,"sourceType":"datasetVersion","datasetId":6860858}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:10:10.365424Z","iopub.execute_input":"2025-03-18T16:10:10.365702Z","iopub.status.idle":"2025-03-18T16:10:10.675906Z","shell.execute_reply.started":"2025-03-18T16:10:10.365679Z","shell.execute_reply":"2025-03-18T16:10:10.675263Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/americannlp-task-2-dataset/maya-test.tsv\n/kaggle/input/americannlp-task-2-dataset/bribri-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-test.tsv\n/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/guarani-train.tsv\n/kaggle/input/americannlp-task-2-dataset/guarani-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/guarani-test.tsv\n/kaggle/input/americannlp-task-2-dataset/maya-train.tsv\n/kaggle/input/americannlp-task-2-dataset/bribri-test.tsv\n/kaggle/input/americannlp-task-2-dataset/maya-dev.tsv\n/kaggle/input/americannlp-task-2-dataset/nahuatl_omitlan-train.tsv\n/kaggle/input/americannlp-task-2-dataset/bribri-train.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%capture\n%pip install Dataset\n%pip install sacrebleu\n%pip install transformers\n%pip install sentencepiece\n%pip install datasets\n%pip install huggingface_hub\n%pip install bitsandbytes\n%pip install -U accelerate\n%pip install -U peft\n%pip install -U trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:10:10.677016Z","iopub.execute_input":"2025-03-18T16:10:10.677481Z","iopub.status.idle":"2025-03-18T16:10:51.099345Z","shell.execute_reply.started":"2025-03-18T16:10:10.677446Z","shell.execute_reply":"2025-03-18T16:10:51.098248Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set environment variable to help with memory allocation\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:10:51.101263Z","iopub.execute_input":"2025-03-18T16:10:51.101592Z","iopub.status.idle":"2025-03-18T16:10:51.105503Z","shell.execute_reply.started":"2025-03-18T16:10:51.101551Z","shell.execute_reply":"2025-03-18T16:10:51.104842Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHUGGINGFACE_TOKEN = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n\n!huggingface-cli login --token $HUGGINGFACE_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:10:51.106849Z","iopub.execute_input":"2025-03-18T16:10:51.107148Z","iopub.status.idle":"2025-03-18T16:10:52.151668Z","shell.execute_reply.started":"2025-03-18T16:10:51.107126Z","shell.execute_reply":"2025-03-18T16:10:52.150849Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nThe token `basic task` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `basic task`\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer,SFTConfig\nfrom trl import setup_chat_format\nfrom transformers import (\n                          AutoTokenizer,\n                          AutoModelForCausalLM,\n                          TrainingArguments,\n                          BitsAndBytesConfig,\n                          pipeline,\n                          Trainer,\n                          DataCollatorWithPadding,\n                          logging)\nfrom sklearn.metrics import (accuracy_score,\n                             classification_report,\n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split\nfrom sacrebleu import corpus_bleu, corpus_chrf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:10:52.152581Z","iopub.execute_input":"2025-03-18T16:10:52.152898Z","iopub.status.idle":"2025-03-18T16:11:17.063708Z","shell.execute_reply.started":"2025-03-18T16:10:52.152875Z","shell.execute_reply":"2025-03-18T16:11:17.063081Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from accelerate import PartialState\ndevice_map={\"\": PartialState().process_index}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:11:17.064383Z","iopub.execute_input":"2025-03-18T16:11:17.064899Z","iopub.status.idle":"2025-03-18T16:11:17.093342Z","shell.execute_reply.started":"2025-03-18T16:11:17.064876Z","shell.execute_reply":"2025-03-18T16:11:17.092461Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Load the data\ntrain_df = pd.read_table('/kaggle/input/americannlp-task-2-dataset/guarani-train.tsv')\ndev_df = pd.read_table('/kaggle/input/americannlp-task-2-dataset/guarani-dev.tsv')\ntest_df = pd.read_table('/kaggle/input/americannlp-task-2-dataset/guarani-test.tsv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:11:17.094135Z","iopub.execute_input":"2025-03-18T16:11:17.094340Z","iopub.status.idle":"2025-03-18T16:11:17.119585Z","shell.execute_reply.started":"2025-03-18T16:11:17.094322Z","shell.execute_reply":"2025-03-18T16:11:17.119026Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"X_train = train_df\nX_eval = dev_df\nX_test_sub = test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:11:17.121649Z","iopub.execute_input":"2025-03-18T16:11:17.121857Z","iopub.status.idle":"2025-03-18T16:11:17.125063Z","shell.execute_reply.started":"2025-03-18T16:11:17.121838Z","shell.execute_reply":"2025-03-18T16:11:17.124295Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"X_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:11:17.126397Z","iopub.execute_input":"2025-03-18T16:11:17.126614Z","iopub.status.idle":"2025-03-18T16:11:17.159668Z","shell.execute_reply.started":"2025-03-18T16:11:17.126596Z","shell.execute_reply":"2025-03-18T16:11:17.159042Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"              ID                                    Source           Change  \\\n0    Guarani0057  Ha’e ombojerekuri umi kutuhakuéra poro’o      PERSON:2_SI   \n1    Guarani0058  Ha’e ombojerekuri umi kutuhakuéra poro’o         TYPE:NEG   \n2    Guarani0059  Ha’e ombojerekuri umi kutuhakuéra poro’o      ASPECT:IPFV   \n3    Guarani0197      Mombe’ukuéra omboty kuri pende arete         TYPE:NEG   \n4    Guarani0198      Mombe’ukuéra omboty kuri pende arete      ASPECT:IPFV   \n..           ...                                       ...              ...   \n173  Guarani0043                                  Che rasy      PERSON:2_SI   \n174  Guarani0044                                  Che rasy      PERSON:3_SI   \n175  Guarani0045                                  Che rasy  PERSON:1_PL_INC   \n176  Guarani0046                                  Che rasy  PERSON:1_PL_EXC   \n177  Guarani0047                                  Che rasy      PERSON:2_PL   \n\n                                              Target  \n0         Nde rembojerekuri umi kutuhakuéra tuicháva  \n1      Ha’e ndombojereikuri umi kutuhakuéra tuicháva  \n2    Ha’e ombojerehina kuri umi kutuhakuéra tuicháva  \n3            Mombe’ukuéra ndombotyi kuri pende arete  \n4          Mombe’ukuéra omboty kuri hína pende arete  \n..                                               ...  \n173                                      Nde nderasy  \n174                                        Ha’e hasy  \n175                                       Ñande rasy  \n176                                       Ore rorasy  \n177                                    Peê penderasy  \n\n[178 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Change</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Guarani0057</td>\n      <td>Ha’e ombojerekuri umi kutuhakuéra poro’o</td>\n      <td>PERSON:2_SI</td>\n      <td>Nde rembojerekuri umi kutuhakuéra tuicháva</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Guarani0058</td>\n      <td>Ha’e ombojerekuri umi kutuhakuéra poro’o</td>\n      <td>TYPE:NEG</td>\n      <td>Ha’e ndombojereikuri umi kutuhakuéra tuicháva</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Guarani0059</td>\n      <td>Ha’e ombojerekuri umi kutuhakuéra poro’o</td>\n      <td>ASPECT:IPFV</td>\n      <td>Ha’e ombojerehina kuri umi kutuhakuéra tuicháva</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Guarani0197</td>\n      <td>Mombe’ukuéra omboty kuri pende arete</td>\n      <td>TYPE:NEG</td>\n      <td>Mombe’ukuéra ndombotyi kuri pende arete</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Guarani0198</td>\n      <td>Mombe’ukuéra omboty kuri pende arete</td>\n      <td>ASPECT:IPFV</td>\n      <td>Mombe’ukuéra omboty kuri hína pende arete</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>Guarani0043</td>\n      <td>Che rasy</td>\n      <td>PERSON:2_SI</td>\n      <td>Nde nderasy</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>Guarani0044</td>\n      <td>Che rasy</td>\n      <td>PERSON:3_SI</td>\n      <td>Ha’e hasy</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>Guarani0045</td>\n      <td>Che rasy</td>\n      <td>PERSON:1_PL_INC</td>\n      <td>Ñande rasy</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>Guarani0046</td>\n      <td>Che rasy</td>\n      <td>PERSON:1_PL_EXC</td>\n      <td>Ore rorasy</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>Guarani0047</td>\n      <td>Che rasy</td>\n      <td>PERSON:2_PL</td>\n      <td>Peê penderasy</td>\n    </tr>\n  </tbody>\n</table>\n<p>178 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Transfer Tags to Instruction","metadata":{}},{"cell_type":"code","source":"def translate_tags_to_instruction(change):\n    \"\"\"\n    Translate the tags in the 'Change' field to full-form instructions, combining multiple instructions with 'and.'\n    \"\"\"\n    # Split the \"Change\" field into tags\n    instruction_tags = change.split(\", \")\n    instructions = []\n\n    # Define mapping dictionaries for each category\n    type_map = {\n        \"NEG\": \"Make the sentence negative\",\n        \"IMP\": \"Change the sentence to imperative mood\",\n        \"AFF\": \"Make the sentence affirmative\"\n    }\n\n    mode_map = {\n        \"DES\": \"Express desire or wish to perform the action\",\n        \"EXH\": \"Change to exhortative mood (encouraging or urging action)\",\n        \"ADVERS\": \"Express that the action was done despite difficulties\",\n        \"POT\": \"Express potential or ability to perform the action\"\n    }\n\n    tense_map = {\n        \"IPFV_HAB\": \"Change to habitual imperfective aspect\",\n        \"IPFV_REC\": \"Change to recent imperfective aspect\",\n        \"IPFV_PROG\": \"Change to progressive imperfective aspect\",\n        \"PRF_PROG\": \"Change to perfect progressive aspect\",\n        \"PRF_REC\": \"Change to recent perfect tense\",\n        \"FUT_POT\": \"Change to potential future tense\",\n        \"FUT_CER\": \"Change to certain future tense\",\n        \"PAS_PLU\": \"Change to pluperfect (past perfect) tense\"\n    }\n\n    aspect_map = {\n        \"IPFV\": \"Change to imperfective aspect\",\n        \"PFV\": \"Change to perfective aspect\",\n        \"INC\": \"Express the beginning or initiation of the action\"\n    }\n\n    voice_map = {\n        \"MID\": \"Change to middle voice\"\n    }\n\n    absnum_map = {\n        \"PL\": \"Make the absolutive argument plural\",\n        \"NI\": \"Remove number marking from the absolutive argument\"\n    }\n\n    person_map = {\n        \"[SUBJ]:1_PL_EXC\": \"Change subject to first person plural exclusive\",\n        \"[SUBJ]:1_PL_INC\": \"Change subject to first person plural inclusive\",\n        \"[SUBJ]:2_PL\": \"Change subject to second person plural\",\n        \"[SUBJ]:3_PL\": \"Change subject to third person plural\",\n        \"[SUBJ]:2_SI\": \"Change subject to second person singular\",\n        \"[SUBJ]:3_SI\": \"Change subject to third person singular\",\n        \"[SUBJ]:NA\": \"Remove person marking\"\n    }\n\n    # Translate each tag into a full-form instruction\n    for tag in instruction_tags:\n        category, value = tag.split(\":\")\n        \n        if category == \"TYPE\":\n            instructions.append(type_map.get(value.strip(), f\"Unknown TYPE: {value.strip()}\"))\n        elif category == \"MODE\":\n            instructions.append(mode_map.get(value.strip(), f\"Unknown MODE: {value.strip()}\"))\n        elif category == \"TENSE\":\n            instructions.append(tense_map.get(value.strip(), f\"Unknown TENSE: {value.strip()}\"))\n        elif category == \"ASPECT\":\n            instructions.append(aspect_map.get(value.strip(), f\"Unknown ASPECT: {value.strip()}\"))\n        elif category == \"VOICE\":\n            instructions.append(voice_map.get(value.strip(), f\"Unknown VOICE: {value.strip()}\"))\n        elif category == \"ABSNUM\":\n            instructions.append(absnum_map.get(value.strip(), f\"Unknown ABSNUM: {value.strip()}\"))\n        elif category.startswith(\"PERSON\"):\n            instructions.append(person_map.get(category + \":\" + value.strip(), f\"Unknown PERSON: {value.strip()}\"))\n        else:\n            instructions.append(f\"Unknown category: {category} with value {value.strip()}\")\n    \n    # Combine all instructions with 'and'\n    return ' and '.join(instructions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:39:37.200835Z","iopub.execute_input":"2025-03-18T16:39:37.201155Z","iopub.status.idle":"2025-03-18T16:39:37.216391Z","shell.execute_reply.started":"2025-03-18T16:39:37.201124Z","shell.execute_reply":"2025-03-18T16:39:37.215613Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# # Example usage\n# data_point = {\n#     \"Source\": \"Ye' shka'\",\n#     \"Change\": \"TYPE:NEG, TENSE:IPFV_REC, PERSON:1_PL_EXC\",\n#     \"Target\": \"Kë̀ ye' shkö̀\"\n# }\n\n# instruction = translate_tags_to_instruction(data_point)\n# print(instruction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:18:01.691180Z","iopub.execute_input":"2025-03-18T16:18:01.691500Z","iopub.status.idle":"2025-03-18T16:18:01.695254Z","shell.execute_reply.started":"2025-03-18T16:18:01.691473Z","shell.execute_reply":"2025-03-18T16:18:01.694086Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Generate Prompt","metadata":{}},{"cell_type":"code","source":"# Define functions for generating prompts\ndef generate_prompt(row):\n    \"\"\"\n    Generate a structured training prompt for a given data point.\n    \"\"\"\n    instruction = translate_tags_to_instruction(row[\"Change\"])\n    return (\n        f\"Language: Guarani\\n\"\n        f\"Task: Transform the Source sentence into the Target sentence based on the given instruction.\\n\\n\"\n        f\"Instruction: {instruction}\\n\"\n        f\"Source: {row['Source']}\\n\"\n        f\"Target: {row['Target']}\"\n    )\n\ndef generate_test_prompt(row):\n    \"\"\"\n    Generate a structured test prompt for a given data point.\n    \"\"\"\n    instruction = translate_tags_to_instruction(row[\"Change\"])\n    return (\n        f\"Language: Guarani\\n\"\n        f\"Task: Transform the Source sentence into the Target sentence based on the given instruction.\\n\\n\"\n        f\"Instruction: {instruction}\\n\"\n        f\"Source: {row['Source']}\\n\"\n        f\"Provide only the transformed Target sentence.\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:27:56.543103Z","iopub.execute_input":"2025-03-18T16:27:56.543386Z","iopub.status.idle":"2025-03-18T16:27:56.547871Z","shell.execute_reply.started":"2025-03-18T16:27:56.543363Z","shell.execute_reply":"2025-03-18T16:27:56.546991Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# # zero sort prompting type 1\n# def generate_prompt(data_point):\n#     \"\"\"\n#     Generate a structured training prompt for a given data point.\n#     \"\"\"\n#     return f\"\"\"Language: Guarani, Rewrite and change the following sentence according to given instruction.\n# Instruction: {data_point[\"Change\"]}\n# Source: {data_point[\"Source\"]}\n# Target: {data_point[\"Target\"]}\n# \"\"\".strip()\n\n# def generate_test_prompt(data_point):\n#     return f\"\"\"\n# Language: Guarani, Rewrite and change the following sentence according to given instruction.\n# Instruction: {data_point[\"Change\"]}\n# Source: {data_point[\"Source\"]}\n# Provide only the Target sentence nothing else.\n# Target:\"\"\".strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:11:17.206684Z","iopub.execute_input":"2025-03-18T16:11:17.206913Z","iopub.status.idle":"2025-03-18T16:11:17.226260Z","shell.execute_reply.started":"2025-03-18T16:11:17.206895Z","shell.execute_reply":"2025-03-18T16:11:17.225533Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Generate prompts for training and evaluation data\nX_train[\"text\"] = X_train.apply(generate_prompt, axis=1)\nX_eval[\"text\"] = X_eval.apply(generate_prompt, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:00.112898Z","iopub.execute_input":"2025-03-18T16:28:00.113275Z","iopub.status.idle":"2025-03-18T16:28:00.121784Z","shell.execute_reply.started":"2025-03-18T16:28:00.113247Z","shell.execute_reply":"2025-03-18T16:28:00.120858Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# # Generate prompts for training and evaluation data\n# X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n# X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:05.704684Z","iopub.execute_input":"2025-03-18T16:28:05.704995Z","iopub.status.idle":"2025-03-18T16:28:05.708615Z","shell.execute_reply.started":"2025-03-18T16:28:05.704950Z","shell.execute_reply":"2025-03-18T16:28:05.707603Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Convert to datasets\ntrain_data = Dataset.from_pandas(X_train[[\"text\"]])\neval_data = Dataset.from_pandas(X_eval[[\"text\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:09.835382Z","iopub.execute_input":"2025-03-18T16:28:09.835681Z","iopub.status.idle":"2025-03-18T16:28:09.849788Z","shell.execute_reply.started":"2025-03-18T16:28:09.835660Z","shell.execute_reply":"2025-03-18T16:28:09.848878Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Create a new DataFrame for test prompts\ntest_data = pd.DataFrame({\n    \"Change\": X_eval[\"Change\"],\n    \"Source\": X_eval[\"Source\"]\n})\n# Generate prompts for test data\nX_test = pd.DataFrame(test_data.apply(lambda row: generate_test_prompt(row), axis=1), columns=[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:12.700894Z","iopub.execute_input":"2025-03-18T16:28:12.701230Z","iopub.status.idle":"2025-03-18T16:28:12.707718Z","shell.execute_reply.started":"2025-03-18T16:28:12.701207Z","shell.execute_reply":"2025-03-18T16:28:12.706708Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Set the device (GPU if available)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:15.320686Z","iopub.execute_input":"2025-03-18T16:28:15.321059Z","iopub.status.idle":"2025-03-18T16:28:15.325319Z","shell.execute_reply.started":"2025-03-18T16:28:15.321028Z","shell.execute_reply":"2025-03-18T16:28:15.324357Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:17.946772Z","iopub.execute_input":"2025-03-18T16:28:17.947087Z","iopub.status.idle":"2025-03-18T16:28:17.951876Z","shell.execute_reply.started":"2025-03-18T16:28:17.947063Z","shell.execute_reply":"2025-03-18T16:28:17.951073Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"# Load the pre-trained model and tokenizer\nbase_model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=\"float16\",\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name,\n    device_map=\"auto\",\n    torch_dtype=\"float16\",\n    quantization_config=bnb_config, \n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:19.855140Z","iopub.execute_input":"2025-03-18T16:28:19.855432Z","iopub.status.idle":"2025-03-18T16:28:28.160345Z","shell.execute_reply.started":"2025-03-18T16:28:19.855410Z","shell.execute_reply":"2025-03-18T16:28:28.159615Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db19a7f9a9944b58b47fefa0280f1d09"}},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"# Move the model to the GPU\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:28.161735Z","iopub.execute_input":"2025-03-18T16:28:28.162076Z","iopub.status.idle":"2025-03-18T16:28:28.176690Z","shell.execute_reply.started":"2025-03-18T16:28:28.162046Z","shell.execute_reply":"2025-03-18T16:28:28.176036Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"# # Define a custom predict function\n# def predict(test, model, tokenizer):\n#     y_pred = []\n    \n#     for i in tqdm(range(len(test))):\n#         prompt = test.iloc[i][\"text\"]\n#         inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n        \n#         # Generate text using the model directly\n#         outputs = model.generate(**inputs, max_length=100, num_beams=4, no_repeat_ngram_size=3).to(device)\n        \n#         generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True).to(device)\n#         transformed_sentence = generated_text.split(\"Target:\")[-1].strip()\n\n#         if transformed_sentence:  \n#             y_pred.append(transformed_sentence)\n#         else:\n#             y_pred.append(\"ERROR\")  # Handle empty outputs\n    \n#     return y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:11:17.575041Z","iopub.status.idle":"2025-03-18T16:11:17.575348Z","shell.execute_reply":"2025-03-18T16:11:17.575240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nfrom transformers import pipeline\nimport string\n\ndef clean_prediction(text):\n    \"\"\"\n    Extracts the expected transformed sentence from the generated output.\n    Stops processing as soon as a punctuation mark is encountered.\n    \"\"\"\n    text = text.strip()\n\n    # Extract text after \"Target:\" marker\n    if \"Target:\" in text:\n        text = text.split(\"Target:\")[-1].strip()\n\n    # Take only the first line to remove unwanted repetitions\n    text = text.split(\"\\n\")[0].strip()\n\n    # Stop at the first punctuation (e.g., period, comma, etc.)\n    for punctuation in string.punctuation:\n        if punctuation in text:\n            text = text.split(punctuation)[0].strip()\n            break\n\n    return text\n\ndef predict(test, model, tokenizer):\n    \"\"\"\n    Generate predictions for the test dataset without using a dataset format.\n    \"\"\"\n    y_pred = []\n    \n    # Define pipeline outside loop for efficiency\n    pipe = pipeline(task=\"text-generation\", \n                    model=model, \n                    tokenizer=tokenizer, \n                    max_new_tokens=20,  # Limit length to avoid extra output\n                    temperature=0.1,  # Make output more deterministic\n                    )  \n\n    for i in tqdm(range(len(test))):\n        prompt = test.iloc[i][\"text\"]  # Use already pre-generated test prompts\n        result = pipe(prompt)\n        \n        generated_text = result[0]['generated_text']\n        transformed_sentence = clean_prediction(generated_text)\n        y_pred.append(transformed_sentence if transformed_sentence else \"ERROR\")  # Handle empty output\n\n    return y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:00:02.805409Z","iopub.execute_input":"2025-03-18T17:00:02.805773Z","iopub.status.idle":"2025-03-18T17:00:02.812022Z","shell.execute_reply.started":"2025-03-18T17:00:02.805736Z","shell.execute_reply":"2025-03-18T17:00:02.811145Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# Evaluate the model before fine-tuning\ny_pred_before_fine_tune = predict(X_test, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:28:30.046094Z","iopub.execute_input":"2025-03-18T16:28:30.046387Z","iopub.status.idle":"2025-03-18T16:29:30.591626Z","shell.execute_reply.started":"2025-03-18T16:28:30.046364Z","shell.execute_reply":"2025-03-18T16:29:30.590878Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n100%|██████████| 79/79 [01:00<00:00,  1.31it/s]\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"# Evaluate the predictions\ndef evaluate(y_true, y_pred):\n    bleu = corpus_bleu(y_pred, [y_true])\n    print(f\"BLEU score: {bleu.score:.2f}\")\n\n    chrf = corpus_chrf(y_pred, [y_true])\n    print(f\"chrF score: {chrf.score:.2f}\")\n\n    for i in range(min(5, len(y_true))):\n        print(f\"\\nMain Prompt: {X_test.iloc[i]['text']}\")\n        print(f\"Expected Sentence: {y_true[i]}\")\n        print(f\"Prediction: {y_pred[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:29:30.592491Z","iopub.execute_input":"2025-03-18T16:29:30.592700Z","iopub.status.idle":"2025-03-18T16:29:30.597123Z","shell.execute_reply.started":"2025-03-18T16:29:30.592682Z","shell.execute_reply":"2025-03-18T16:29:30.596371Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Evaluate the model\ny_true = X_eval[\"Target\"]\n\n# Evaluate the model before fine-tuning\nprint(\"\\nOriginal Model Evaluation Before Fine Tuning:\")\nevaluate(y_true.tolist(), y_pred_before_fine_tune)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:29:30.598301Z","iopub.execute_input":"2025-03-18T16:29:30.598552Z","iopub.status.idle":"2025-03-18T16:29:30.632476Z","shell.execute_reply.started":"2025-03-18T16:29:30.598532Z","shell.execute_reply":"2025-03-18T16:29:30.631847Z"}},"outputs":[{"name":"stdout","text":"\nOriginal Model Evaluation Before Fine Tuning:\nBLEU score: 8.47\nchrF score: 51.63\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Make the sentence affirmative\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Ore rombyai kuri\nPrediction: Ore ndorombyai kuri.\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Unknown TENSE: FUT_SIM\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Ore ndorombyaita\nPrediction: Ore ndorombyai kuri.\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Change subject to first person plural inclusive\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Ñande nañambyai kuri\nPrediction: Ore ndorombyai kuri, ore ndorombya kuri\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Unknown PERSON: 1_SI\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Che nambyai kuri\nPrediction: Unknown PERSON: 1SI\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Change subject to second person plural\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Peẽ napembyai kuri\nPrediction: Ore ndorombyai kuri?\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# Define LoRA configuration\ndef find_all_linear_names(model):\n    cls = torch.nn.Linear\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:30:57.349617Z","iopub.execute_input":"2025-03-18T16:30:57.349938Z","iopub.status.idle":"2025-03-18T16:30:57.355774Z","shell.execute_reply.started":"2025-03-18T16:30:57.349916Z","shell.execute_reply":"2025-03-18T16:30:57.354733Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=4,\n    lora_alpha=8,\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:31:00.087220Z","iopub.execute_input":"2025-03-18T16:31:00.087534Z","iopub.status.idle":"2025-03-18T16:31:00.091673Z","shell.execute_reply.started":"2025-03-18T16:31:00.087507Z","shell.execute_reply":"2025-03-18T16:31:00.090874Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Set up training arguments\ntraining_arguments = SFTConfig(\n    output_dir=\"./results\",\n    num_train_epochs=5,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    save_steps=1000,\n    dataset_text_field=\"text\",\n    max_seq_length=512,\n    packing=False,\n    logging_steps=500,\n    learning_rate=2e-4,\n    weight_decay=0.01,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"none\",\n    eval_strategy=\"steps\",\n    eval_steps=50,  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:31:02.713171Z","iopub.execute_input":"2025-03-18T16:31:02.713455Z","iopub.status.idle":"2025-03-18T16:31:02.741549Z","shell.execute_reply.started":"2025-03-18T16:31:02.713433Z","shell.execute_reply":"2025-03-18T16:31:02.740872Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Initialize the SFTTrainer\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=lora_config,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:31:05.332890Z","iopub.execute_input":"2025-03-18T16:31:05.333224Z","iopub.status.idle":"2025-03-18T16:31:06.571050Z","shell.execute_reply.started":"2025-03-18T16:31:05.333199Z","shell.execute_reply":"2025-03-18T16:31:06.570412Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-55-1a90b2d52780>:2: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n  trainer = SFTTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"968fd776208f4405be948b61a76aa523"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dc56bd24f864d4ba0e1c8c39ff33114"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9764f54d79934f39b90937102d222aca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f598a2f1a7a34a33bbb1f6b1e857f47a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting eval dataset to ChatML:   0%|          | 0/79 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14e29b1e774e4d088d384988cdcebc5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/79 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3292b85684645ca8396bf82ce3769b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/79 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c6c14efaeba463fb9f06fe95f5c39de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/79 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d923e76c11154a6193c8a232d038d3f9"}},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T16:31:14.142907Z","iopub.execute_input":"2025-03-18T16:31:14.143253Z","iopub.status.idle":"2025-03-18T16:38:03.353316Z","shell.execute_reply.started":"2025-03-18T16:31:14.143225Z","shell.execute_reply":"2025-03-18T16:38:03.352398Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='445' max='445' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [445/445 06:47, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>No log</td>\n      <td>1.314274</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>No log</td>\n      <td>1.263875</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>No log</td>\n      <td>1.264559</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>No log</td>\n      <td>1.295768</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>No log</td>\n      <td>1.314627</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>No log</td>\n      <td>1.355332</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>No log</td>\n      <td>1.366701</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>No log</td>\n      <td>1.360080</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=445, training_loss=0.980946195795295, metrics={'train_runtime': 408.7522, 'train_samples_per_second': 2.177, 'train_steps_per_second': 1.089, 'total_flos': 920921477314560.0, 'train_loss': 0.980946195795295})"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"# Evaluate the model after fine-tuning\ny_pred_after_fine_tune = predict(X_test, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:00:09.431076Z","iopub.execute_input":"2025-03-18T17:00:09.431380Z","iopub.status.idle":"2025-03-18T17:01:48.277811Z","shell.execute_reply.started":"2025-03-18T17:00:09.431360Z","shell.execute_reply":"2025-03-18T17:01:48.276864Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n100%|██████████| 79/79 [01:38<00:00,  1.25s/it]\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# Evaluate the model\ny_true = X_eval[\"Target\"]\n\n# Evaluate the model before fine-tuning\nprint(\"\\nOriginal Model Evaluation After Fine Tuning:\")\nevaluate(y_true.tolist(), y_pred_after_fine_tune)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:03:17.566617Z","iopub.execute_input":"2025-03-18T17:03:17.567084Z","iopub.status.idle":"2025-03-18T17:03:17.588348Z","shell.execute_reply.started":"2025-03-18T17:03:17.567057Z","shell.execute_reply":"2025-03-18T17:03:17.587468Z"}},"outputs":[{"name":"stdout","text":"\nOriginal Model Evaluation After Fine Tuning:\nBLEU score: 22.99\nchrF score: 58.50\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Make the sentence affirmative\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Ore rombyai kuri\nPrediction: Language\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Unknown TENSE: FUT_SIM\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Ore ndorombyaita\nPrediction: Ore ndorombyáita kuri\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Change subject to first person plural inclusive\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Ñande nañambyai kuri\nPrediction: Ñande ndañomi kuri\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Unknown PERSON: 1_SI\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Che nambyai kuri\nPrediction: Che ndaorombyai kuri\n\nMain Prompt: Language: Guarani\nTask: Transform the Source sentence into the Target sentence based on the given instruction.\n\nInstruction: Change subject to second person plural\nSource: Ore ndorombyai kuri\nProvide only the transformed Target sentence.\nExpected Sentence: Peẽ napembyai kuri\nPrediction: Nde nderejapói kuri\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"## Dev Submission","metadata":{}},{"cell_type":"code","source":"dev_pd = pd.DataFrame(y_pred_after_fine_tune, columns=['Values'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:04:34.791747Z","iopub.execute_input":"2025-03-18T17:04:34.792138Z","iopub.status.idle":"2025-03-18T17:04:34.796628Z","shell.execute_reply.started":"2025-03-18T17:04:34.792111Z","shell.execute_reply":"2025-03-18T17:04:34.795757Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"dev_pd.to_csv('syntax_squad_guarani_dev_output.tsv', sep='\\t', index=False, header=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:04:37.525194Z","iopub.execute_input":"2025-03-18T17:04:37.525509Z","iopub.status.idle":"2025-03-18T17:04:37.535263Z","shell.execute_reply.started":"2025-03-18T17:04:37.525480Z","shell.execute_reply":"2025-03-18T17:04:37.534330Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(\"syntax_squad_guarani_dev_output.tsv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:04:39.904382Z","iopub.execute_input":"2025-03-18T17:04:39.904676Z","iopub.status.idle":"2025-03-18T17:04:39.910212Z","shell.execute_reply.started":"2025-03-18T17:04:39.904654Z","shell.execute_reply":"2025-03-18T17:04:39.909442Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/syntax_squad_guarani_dev_output.tsv","text/html":"<a href='syntax_squad_guarani_dev_output.tsv' target='_blank'>syntax_squad_guarani_dev_output.tsv</a><br>"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"## Test Submission","metadata":{}},{"cell_type":"code","source":"# Create a new DataFrame for test prompts\ntest_data_sub = pd.DataFrame({\n    \"Change\": X_test_sub[\"Change\"],\n    \"Source\": X_test_sub[\"Source\"]\n})\n# Generate prompts for test data\nX_test_sub = pd.DataFrame(test_data_sub.apply(lambda row: generate_test_prompt(row), axis=1), columns=[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:04:42.761889Z","iopub.execute_input":"2025-03-18T17:04:42.762199Z","iopub.status.idle":"2025-03-18T17:04:42.771308Z","shell.execute_reply.started":"2025-03-18T17:04:42.762175Z","shell.execute_reply":"2025-03-18T17:04:42.770530Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# Evaluate the model before fine-tuning\ny_pred_test = predict(X_test_sub, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:04:45.644724Z","iopub.execute_input":"2025-03-18T17:04:45.645062Z","iopub.status.idle":"2025-03-18T17:12:13.380194Z","shell.execute_reply.started":"2025-03-18T17:04:45.645030Z","shell.execute_reply":"2025-03-18T17:12:13.379297Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n100%|██████████| 364/364 [07:27<00:00,  1.23s/it]\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"test_pd = pd.DataFrame(y_pred_test, columns=['Values'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:12:13.381426Z","iopub.execute_input":"2025-03-18T17:12:13.381717Z","iopub.status.idle":"2025-03-18T17:12:13.385929Z","shell.execute_reply.started":"2025-03-18T17:12:13.381693Z","shell.execute_reply":"2025-03-18T17:12:13.385048Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"test_pd.to_csv('syntax_squad_guarani_test_output.tsv', sep='\\t', index=False, header=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:12:13.387394Z","iopub.execute_input":"2025-03-18T17:12:13.387622Z","iopub.status.idle":"2025-03-18T17:12:13.401094Z","shell.execute_reply.started":"2025-03-18T17:12:13.387601Z","shell.execute_reply":"2025-03-18T17:12:13.400414Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(\"syntax_squad_guarani_test_output.tsv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T17:12:13.401871Z","iopub.execute_input":"2025-03-18T17:12:13.402089Z","iopub.status.idle":"2025-03-18T17:12:13.415752Z","shell.execute_reply.started":"2025-03-18T17:12:13.402069Z","shell.execute_reply":"2025-03-18T17:12:13.415126Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/syntax_squad_guarani_test_output.tsv","text/html":"<a href='syntax_squad_guarani_test_output.tsv' target='_blank'>syntax_squad_guarani_test_output.tsv</a><br>"},"metadata":{}}],"execution_count":70}]}